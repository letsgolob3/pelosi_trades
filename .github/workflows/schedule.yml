name: Daily Scraper

on:
  schedule:
    - cron: "0 9 * * *"  # Runs daily at 9 AM UTC
  workflow_dispatch:  # Allows manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v3
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: |
          sudo apt-get update
          pip install -r requirements.txt

      - name: Install Chrome
        run: |
          wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable=132.0.6834.160-1
        
      - name: Install ChromeDriver
        run: |
          CHROMEDRIVER_VERSION=132.0.6834.160
          wget -N "https://chromedriver.storage.googleapis.com/${CHROMEDRIVER_VERSION}/chromedriver_linux64.zip"
          unzip chromedriver_linux64.zip
          sudo mv chromedriver /usr/local/bin/
          sudo chmod +x /usr/local/bin/chromedriver
        

      - name: Set Environment Variables from GitHub Secrets
        run: |
          echo "EMAIL_USER=${{ secrets.EMAIL_USER }}" >> $GITHUB_ENV
          echo "EMAIL_PASSWORD=${{ secrets.EMAIL_PASSWORD }}" >> $GITHUB_ENV

      - name: Run the script
        env:
          DISPLAY: ":99"  # Required for Selenium in headless mode
        run: python pelosi_trader.py
